# This CITATION.cff file was generated with cffinit.
# Visit https://bit.ly/cffinit to generate yours today!

cff-version: 1.2.0
title: ' efficient-RL-for-images '
message: >-
  If you use this software, please cite it using the
  metadata from this file.
type: software
authors:
  - given-names: Peter
    family-names: Loxley
identifiers:
  - type: doi
    value: 10.48550/arXiv.2412.08893
abstract: >-
  Reinforcement learning solves optimal control and
  sequential decision problems widely found in

  control systems engineering, robotics, and artificial
  intelligence. This work investigates optimal

  control over a sequence of natural images. The problem is
  formalized, and general conditions are

  derived for an image to be sufficient for implementing an
  optimal policy. Reinforcement learning

  is shown to be efficient only for certain types of image
  representations. This is demonstrated by

  developing a reinforcement learning benchmark that scales
  easily with number of states and length

  of horizon, and has optimal policies that are easily
  distinguished from suboptimal policies. Image

  representations given by overcomplete sparse codes are
  found to be computationally efficient for

  optimal control, using fewer computational resources to
  learn and evaluate optimal policies. For

  natural images of fixed size, representing each image as
  an overcomplete sparse code in a linear

  network is shown to increase network storage capacity by
  orders of magnitude beyond that possible

  for any complete code, allowing larger tasks with many
  more states to be solved. Sparse codes can

  be generated by devices with low energy requirements and
  low computational overhead.
keywords:
  - Natural image sequences
  - Optimal policies
  - Overcomplete sparse codes
  - Sufficient statistic
license: MIT
